{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZFfaHTV+GczBlD7NWjkDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohoobot/works/blob/main/experiment_yes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate bert_score rouge_score nltk --quiet\n"
      ],
      "metadata": {
        "id": "4uzLDFu0wIL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaSLa55rqyqJ"
      },
      "outputs": [],
      "source": [
        "# 10\n",
        "# 80+æ ·æœ¬ï¼Œå¸¦æ­Œåæœªæ¸…æ´—\n",
        "# musicgen_scene_music_pairs_train.jsonl\n",
        "# musicgen_scene_music_pairs_test.jsonl\n",
        "# few-shot k=2\n",
        "# 1 epoch\n",
        "\n",
        "# âœ… å®‰è£…ä¸€æ¬¡å³å¯\n",
        "# !pip install evaluate bert_score rouge_score nltk --quiet\n",
        "# !pip install git+https://github.com/google-research/bleurt.git\n",
        "\n",
        "# âœ… å¯¼å…¥æ‰€éœ€æ¨¡å—\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# âœ… è¯»å–æ•°æ®\n",
        "with open(\"musicgen_scene_music_pairs_train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "with open(\"musicgen_scene_music_pairs_test.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# âœ… è®¾ç½® API\n",
        "QWEN_API_KEY = \"sk-\"\n",
        "QWEN_API_URL = \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\"\n",
        "\n",
        "# âœ… æ„å»º few-shot prompt\n",
        "def build_few_shot_messages(k=2):\n",
        "    examples = random.sample(train_data, k)\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a music cognition expert converting restaurant scene descriptions into music prompts suitable for MusicGen.\"}]\n",
        "    for ex in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Scene: {ex['scene']}\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ex['music']})\n",
        "    return messages\n",
        "\n",
        "# âœ… è°ƒç”¨ Qwen API\n",
        "def generate_music_description(scene_desc):\n",
        "    messages = build_few_shot_messages()\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Scene: {scene_desc}\"})\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {QWEN_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen2.5-14b-instruct\",\n",
        "        \"input\": {\"messages\": messages},\n",
        "        \"parameters\": {\"temperature\": 0.5, \"max_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(QWEN_API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"output\", {}).get(\"text\", \"\").strip()\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "\n",
        "# âœ… éå†æµ‹è¯•é›†åšæ¨ç†\n",
        "generated = []\n",
        "for item in tqdm(test_data):\n",
        "    scene = item[\"scene\"]\n",
        "    reference = item[\"music\"]\n",
        "    prediction = generate_music_description(scene)\n",
        "    generated.append({\"scene\": scene, \"reference\": reference, \"prediction\": prediction})\n",
        "\n",
        "# âœ… æå–ç”¨äºè¯„ä¼°çš„æ–‡æœ¬\n",
        "references = [x[\"reference\"] for x in generated]\n",
        "predictions = [x[\"prediction\"] for x in generated]\n",
        "\n",
        "# âœ… è¯„ä¼°ï¼šBLEUï¼ˆä½¿ç”¨ NLTKï¼‰\n",
        "smoothie = SmoothingFunction().method4\n",
        "bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "# âœ… è¯„ä¼°ï¼šROUGE / METEOR / BERTScore / BLEURT\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "meteor = evaluate.load(\"meteor\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "bleurt = evaluate.load(\"bleurt\", module_type=\"metric\", checkpoint=\"bleurt-base-128\")\n",
        "\n",
        "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "bleurt_result = bleurt.compute(predictions=predictions, references=references)\n",
        "\n",
        "# âœ… è¾“å‡ºè¯„ä¼°ç»“æœ\n",
        "print(\"ğŸ¯ Evaluation Results:\")\n",
        "print(f\"BLEU: {avg_bleu:.4f}\")\n",
        "print(f\"ROUGE-L: {rouge_result['rougeL']:.4f}\")\n",
        "print(f\"METEOR: {meteor_result['meteor']:.4f}\")\n",
        "print(f\"BERTScore (F1): {sum(bertscore_result['f1'])/len(bertscore_result['f1']):.4f}\")\n",
        "print(f\"BLEURT: {sum(bleurt_result['scores'])/len(bleurt_result['scores']):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21 32\n",
        "# 80+æ ·æœ¬ï¼Œå·²ç»æ›¿æ¢ä¸º this is aï¼Œå·²æ¸…æ´—\n",
        "# musicgen_scene_music_pairs_train_v2.jsonl\n",
        "# musicgen_scene_music_pairs_test_v2.jsonl\n",
        "# few-shot k=4\n",
        "# 1 epoch\n",
        "\n",
        "# âœ… å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
        "# !pip install evaluate bert_score rouge_score nltk --quiet\n",
        "# !pip install git+https://github.com/google-research/bleurt.git\n",
        "\n",
        "# âœ… å¯¼å…¥æ¨¡å—\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# âœ… è¯»å–æ–°æ•°æ®é›†ï¼ˆå·²ç»æ›¿æ¢äº† is a ä¸º this is aï¼‰\n",
        "with open(\"musicgen_scene_music_pairs_train_v2.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "with open(\"musicgen_scene_music_pairs_test_v2.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# âœ… Qwen API è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ API Keyï¼‰\n",
        "QWEN_API_KEY = \"sk-\"\n",
        "QWEN_API_URL = \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\"\n",
        "\n",
        "# âœ… æ„é€  few-shot prompt\n",
        "def build_few_shot_messages(k=2):\n",
        "    examples = random.sample(train_data, k)\n",
        "    messages = [{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a music cognition expert. Convert restaurant scene descriptions into MusicGen-style music prompts. Describe BPM, genre, mood, key, instrumentation.\"\n",
        "    }]\n",
        "    for ex in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Scene: {ex['scene']}\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ex['music']})\n",
        "    return messages\n",
        "\n",
        "# âœ… è°ƒç”¨ Qwen æ¥å£\n",
        "def generate_music_description(scene_desc):\n",
        "    messages = build_few_shot_messages(k=2)\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Scene: {scene_desc}\"})\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {QWEN_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen2.5-14b-instruct\",\n",
        "        \"input\": {\"messages\": messages},\n",
        "        \"parameters\": {\"temperature\": 0.5, \"max_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(QWEN_API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"output\", {}).get(\"text\", \"\").strip()\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "\n",
        "# âœ… éå†æµ‹è¯•é›†ç”Ÿæˆé¢„æµ‹\n",
        "results = []\n",
        "for sample in tqdm(test_data):\n",
        "    pred = generate_music_description(sample[\"scene\"])\n",
        "    results.append({\n",
        "        \"scene\": sample[\"scene\"],\n",
        "        \"reference\": sample[\"music\"],\n",
        "        \"prediction\": pred\n",
        "    })\n",
        "\n",
        "# âœ… ä¿å­˜ç”Ÿæˆç»“æœ\n",
        "output_path = \"/content/qwen_fewshot_outputs_v2.json\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… è¯„ä¼°éƒ¨åˆ†\n",
        "references = [x[\"reference\"] for x in results]\n",
        "predictions = [x[\"prediction\"] for x in results]\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "meteor = evaluate.load(\"meteor\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "smoothie = SmoothingFunction().method4\n",
        "bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "avg_bertscore_f1 = sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"])\n",
        "\n",
        "# âœ… è¾“å‡ºè¯„ä¼°ç»“æœ\n",
        "print(\"\\nğŸ¯ Evaluation Results (Qwen Few-shot â†’ Music Description):\")\n",
        "print(f\"BLEU: {avg_bleu:.4f}\")\n",
        "print(f\"ROUGE-L: {rouge_result['rougeL']:.4f}\")\n",
        "print(f\"METEOR: {meteor_result['meteor']:.4f}\")\n",
        "print(f\"BERTScore (F1): {avg_bertscore_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "qbnuYBjg1yaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 40\n",
        "# 185æ ·æœ¬ï¼Œæœªæ¸…æ´—\n",
        "# musicgen_scene_music_pairs_all_train.jsonl\n",
        "# musicgen_scene_music_pairs_all_test.jsonl\n",
        "# few-shot k=4\n",
        "# 1 epoch\n",
        "\n",
        "# âœ… å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
        "# !pip install evaluate bert_score rouge_score nltk --quiet\n",
        "# !pip install git+https://github.com/google-research/bleurt.git\n",
        "\n",
        "# âœ… å¯¼å…¥æ¨¡å—\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# âœ… è¯»å–æ–°æ•°æ®é›†ï¼ˆ185æ¡å®Œæ•´æ•°æ®ï¼Œæ ¼å¼å·²æ ‡å‡†åŒ–ï¼‰\n",
        "with open(\"musicgen_scene_music_pairs_all_train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "with open(\"musicgen_scene_music_pairs_all_test.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# âœ… Qwen API è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ API Keyï¼‰\n",
        "QWEN_API_KEY = \"sk-\"\n",
        "QWEN_API_URL = \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\"\n",
        "\n",
        "# âœ… æ„é€  few-shot promptï¼ˆä½¿ç”¨ 4 æ¡ï¼‰\n",
        "def build_few_shot_messages(k=4):\n",
        "    examples = random.sample(train_data, k)\n",
        "    messages = [{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a music cognition expert. Convert restaurant scene descriptions into MusicGen-style music prompts. Describe BPM, genre, mood, key, instrumentation.\"\n",
        "    }]\n",
        "    for ex in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Scene: {ex['scene']}\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ex['music']})\n",
        "    return messages\n",
        "\n",
        "# âœ… è°ƒç”¨ Qwen æ¥å£\n",
        "def generate_music_description(scene_desc):\n",
        "    messages = build_few_shot_messages(k=4)\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Scene: {scene_desc}\"})\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {QWEN_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen2.5-14b-instruct\",\n",
        "        \"input\": {\"messages\": messages},\n",
        "        \"parameters\": {\"temperature\": 0.5, \"max_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(QWEN_API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"output\", {}).get(\"text\", \"\").strip()\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "\n",
        "# âœ… éå†æµ‹è¯•é›†ç”Ÿæˆé¢„æµ‹\n",
        "results = []\n",
        "for sample in tqdm(test_data):\n",
        "    pred = generate_music_description(sample[\"scene\"])\n",
        "    results.append({\n",
        "        \"scene\": sample[\"scene\"],\n",
        "        \"reference\": sample[\"music\"],\n",
        "        \"prediction\": pred\n",
        "    })\n",
        "\n",
        "# âœ… ä¿å­˜ç”Ÿæˆç»“æœ\n",
        "output_path = \"/content/qwen_fewshot_outputs_full.json\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… è¯„ä¼°éƒ¨åˆ†\n",
        "references = [x[\"reference\"] for x in results]\n",
        "predictions = [x[\"prediction\"] for x in results]\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "meteor = evaluate.load(\"meteor\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "smoothie = SmoothingFunction().method4\n",
        "bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "avg_bertscore_f1 = sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"])\n",
        "\n",
        "# âœ… è¾“å‡ºè¯„ä¼°ç»“æœ\n",
        "print(\"\\nğŸ¯ Evaluation Results (Qwen Few-shot â†’ Music Description):\")\n",
        "print(f\"BLEU: {avg_bleu:.4f}\")\n",
        "print(f\"ROUGE-L: {rouge_result['rougeL']:.4f}\")\n",
        "print(f\"METEOR: {meteor_result['meteor']:.4f}\")\n",
        "print(f\"BERTScore (F1): {avg_bertscore_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "TrS0LuCS5m6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 50\n",
        "# 185æ ·æœ¬ï¼Œå·²æ¸…æ´—\n",
        "# musicgen_scene_music_pairs_all_cleaned_train.jsonl\n",
        "# musicgen_scene_music_pairs_all_cleaned_test.jsonl\n",
        "# few-shot k=4\n",
        "# 1 epoch\n",
        "\n",
        "\n",
        "# âœ… å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
        "# !pip install evaluate bert_score rouge_score nltk --quiet\n",
        "# !pip install git+https://github.com/google-research/bleurt.git\n",
        "\n",
        "# âœ… å¯¼å…¥æ¨¡å—\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# âœ… è¯»å–æ–°æ•°æ®é›†ï¼ˆ185æ¡å®Œæ•´æ•°æ®ï¼Œæ ¼å¼å·²æ ‡å‡†åŒ–ï¼‰\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_test.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# âœ… Qwen API è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ API Keyï¼‰\n",
        "QWEN_API_KEY = \"sk-\"\n",
        "QWEN_API_URL = \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\"\n",
        "\n",
        "# âœ… æ„é€  few-shot promptï¼ˆä½¿ç”¨ 4 æ¡ï¼‰\n",
        "def build_few_shot_messages(k=4):\n",
        "    examples = random.sample(train_data, k)\n",
        "    messages = [{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a music cognition expert. Convert restaurant scene descriptions into MusicGen-style music prompts. Describe BPM, genre, mood, key, instrumentation.\"\n",
        "    }]\n",
        "    for ex in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Scene: {ex['scene']}\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ex['music']})\n",
        "    return messages\n",
        "\n",
        "# âœ… è°ƒç”¨ Qwen æ¥å£\n",
        "def generate_music_description(scene_desc):\n",
        "    messages = build_few_shot_messages(k=4)\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Scene: {scene_desc}\"})\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {QWEN_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen2.5-14b-instruct\",\n",
        "        \"input\": {\"messages\": messages},\n",
        "        \"parameters\": {\"temperature\": 0.5, \"max_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(QWEN_API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"output\", {}).get(\"text\", \"\").strip()\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "\n",
        "# âœ… éå†æµ‹è¯•é›†ç”Ÿæˆé¢„æµ‹\n",
        "results = []\n",
        "for sample in tqdm(test_data):\n",
        "    pred = generate_music_description(sample[\"scene\"])\n",
        "    results.append({\n",
        "        \"scene\": sample[\"scene\"],\n",
        "        \"reference\": sample[\"music\"],\n",
        "        \"prediction\": pred\n",
        "    })\n",
        "\n",
        "# âœ… ä¿å­˜ç”Ÿæˆç»“æœ\n",
        "output_path = \"/content/qwen_fewshot_outputs_full.json\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… è¯„ä¼°éƒ¨åˆ†\n",
        "references = [x[\"reference\"] for x in results]\n",
        "predictions = [x[\"prediction\"] for x in results]\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "meteor = evaluate.load(\"meteor\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "smoothie = SmoothingFunction().method4\n",
        "bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "avg_bertscore_f1 = sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"])\n",
        "\n",
        "# âœ… è¾“å‡ºè¯„ä¼°ç»“æœ\n",
        "print(\"\\nğŸ¯ Evaluation Results (Qwen Few-shot â†’ Music Description):\")\n",
        "print(f\"BLEU: {avg_bleu:.4f}\")\n",
        "print(f\"ROUGE-L: {rouge_result['rougeL']:.4f}\")\n",
        "print(f\"METEOR: {meteor_result['meteor']:.4f}\")\n",
        "print(f\"BERTScore (F1): {avg_bertscore_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "bkK9PrgX9yi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 63\n",
        "# 185æ ·æœ¬ï¼Œå·²æ¸…æ´—\n",
        "# musicgen_scene_music_pairs_all_cleaned_train.jsonl\n",
        "# musicgen_scene_music_pairs_all_cleaned_test.jsonl\n",
        "# few-shot k=6\n",
        "# 5 epoch\n",
        "\n",
        "# âœ… å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
        "# !pip install evaluate bert_score rouge_score nltk --quiet\n",
        "# !pip install git+https://github.com/google-research/bleurt.git\n",
        "\n",
        "# âœ… å¯¼å…¥æ¨¡å—\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âœ… è¯»å–æ–°æ•°æ®é›†ï¼ˆ185æ¡å®Œæ•´æ•°æ®ï¼Œæ ¼å¼å·²æ ‡å‡†åŒ–ï¼‰\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_test.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# âœ… Qwen API è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ API Keyï¼‰\n",
        "QWEN_API_KEY = \"sk-\"\n",
        "QWEN_API_URL = \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\"\n",
        "\n",
        "# âœ… æ„é€  few-shot promptï¼ˆæ¯è½® 6 æ¡ï¼‰\n",
        "def build_few_shot_messages(k=6):\n",
        "    examples = random.sample(train_data, k)\n",
        "    messages = [{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a music cognition expert. Convert restaurant scene descriptions into MusicGen-style music prompts. Describe BPM, genre, mood, key, instrumentation.\"\n",
        "    }]\n",
        "    for ex in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Scene: {ex['scene']}\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ex['music']})\n",
        "    return messages\n",
        "\n",
        "# âœ… è°ƒç”¨ Qwen æ¥å£\n",
        "def generate_music_description(scene_desc, k=6):\n",
        "    messages = build_few_shot_messages(k)\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Scene: {scene_desc}\"})\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {QWEN_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen2.5-14b-instruct\",\n",
        "        \"input\": {\"messages\": messages},\n",
        "        \"parameters\": {\"temperature\": 0.5, \"max_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(QWEN_API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"output\", {}).get(\"text\", \"\").strip()\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "\n",
        "# âœ… å¤šè½®éªŒè¯ï¼ˆé»˜è®¤ 5 è½®ï¼‰\n",
        "epochs = 5\n",
        "results_by_round = []\n",
        "\n",
        "for round_idx in range(epochs):\n",
        "    print(f\"\\nğŸš€ Round {round_idx + 1}/{epochs}\")\n",
        "    round_results = []\n",
        "    for sample in tqdm(test_data):\n",
        "        pred = generate_music_description(sample[\"scene\"], k=6)\n",
        "        round_results.append({\n",
        "            \"scene\": sample[\"scene\"],\n",
        "            \"reference\": sample[\"music\"],\n",
        "            \"prediction\": pred\n",
        "        })\n",
        "\n",
        "    references = [x[\"reference\"] for x in round_results]\n",
        "    predictions = [x[\"prediction\"] for x in round_results]\n",
        "\n",
        "    rouge = evaluate.load(\"rouge\")\n",
        "    meteor = evaluate.load(\"meteor\")\n",
        "    bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "    meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "    bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "    avg_bertscore_f1 = sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"])\n",
        "\n",
        "    results_by_round.append({\n",
        "        \"BLEU\": avg_bleu,\n",
        "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
        "        \"METEOR\": meteor_result[\"meteor\"],\n",
        "        \"BERTScore_F1\": avg_bertscore_f1\n",
        "    })\n",
        "\n",
        "# âœ… å¯è§†åŒ–è¯„ä¼°æŒ‡æ ‡\n",
        "rounds = list(range(1, epochs + 1))\n",
        "plt.figure(figsize=(10, 6))\n",
        "for metric in [\"BLEU\", \"ROUGE-L\", \"METEOR\", \"BERTScore_F1\"]:\n",
        "    scores = [res[metric] for res in results_by_round]\n",
        "    plt.plot(rounds, scores, label=metric)\n",
        "\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Qwen Few-shot Multi-round Evaluation\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# âœ… è¾“å‡ºæ¯è½®å¾—åˆ†è¡¨æ ¼\n",
        "for idx, scores in enumerate(results_by_round):\n",
        "    print(f\"\\nğŸ“Š Round {idx + 1} Scores:\")\n",
        "    for k, v in scores.items():\n",
        "        print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "ux4bKQU_Cvck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 74\n",
        "# 185æ ·æœ¬ï¼Œå·²æ¸…æ´—\n",
        "# musicgen_scene_music_pairs_all_cleaned_train.jsonl\n",
        "# musicgen_scene_music_pairs_all_cleaned_test.jsonl\n",
        "# few-shot k=10\n",
        "# 5 epoch\n",
        "\n",
        "# âœ… å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
        "# !pip install evaluate bert_score rouge_score nltk --quiet\n",
        "# !pip install git+https://github.com/google-research/bleurt.git\n",
        "\n",
        "# âœ… å¯¼å…¥æ¨¡å—\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âœ… è¯»å–æ–°æ•°æ®é›†ï¼ˆ185æ¡å®Œæ•´æ•°æ®ï¼Œæ ¼å¼å·²æ ‡å‡†åŒ–ï¼‰\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_test.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# âœ… Qwen API è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ API Keyï¼‰\n",
        "QWEN_API_KEY = \"sk-\"\n",
        "QWEN_API_URL = \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\"\n",
        "\n",
        "# âœ… æ„é€  few-shot promptï¼ˆæ¯è½® 10 æ¡ï¼‰\n",
        "def build_few_shot_messages(k=10):\n",
        "    examples = random.sample(train_data, k)\n",
        "    messages = [{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a music cognition expert. Convert restaurant scene descriptions into MusicGen-style music prompts. Describe BPM, genre, mood, key, instrumentation.\"\n",
        "    }]\n",
        "    for ex in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Scene: {ex['scene']}\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ex['music']})\n",
        "    return messages\n",
        "\n",
        "# âœ… è°ƒç”¨ Qwen æ¥å£\n",
        "def generate_music_description(scene_desc, k=10):\n",
        "    messages = build_few_shot_messages(k)\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Scene: {scene_desc}\"})\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {QWEN_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen2.5-14b-instruct\",\n",
        "        \"input\": {\"messages\": messages},\n",
        "        \"parameters\": {\"temperature\": 0.5, \"max_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(QWEN_API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"output\", {}).get(\"text\", \"\").strip()\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "\n",
        "# âœ… å¤šè½®éªŒè¯ï¼ˆé»˜è®¤ 5 è½®ï¼‰\n",
        "epochs = 5\n",
        "results_by_round = []\n",
        "\n",
        "for round_idx in range(epochs):\n",
        "    print(f\"\\nğŸš€ Round {round_idx + 1}/{epochs}\")\n",
        "    round_results = []\n",
        "    for sample in tqdm(test_data):\n",
        "        pred = generate_music_description(sample[\"scene\"], k=10)\n",
        "        round_results.append({\n",
        "            \"scene\": sample[\"scene\"],\n",
        "            \"reference\": sample[\"music\"],\n",
        "            \"prediction\": pred\n",
        "        })\n",
        "\n",
        "    references = [x[\"reference\"] for x in round_results]\n",
        "    predictions = [x[\"prediction\"] for x in round_results]\n",
        "\n",
        "    rouge = evaluate.load(\"rouge\")\n",
        "    meteor = evaluate.load(\"meteor\")\n",
        "    bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "    meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "    bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "    avg_bertscore_f1 = sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"])\n",
        "\n",
        "    results_by_round.append({\n",
        "        \"BLEU\": avg_bleu,\n",
        "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
        "        \"METEOR\": meteor_result[\"meteor\"],\n",
        "        \"BERTScore_F1\": avg_bertscore_f1\n",
        "    })\n",
        "\n",
        "# âœ… å¯è§†åŒ–è¯„ä¼°æŒ‡æ ‡\n",
        "rounds = list(range(1, epochs + 1))\n",
        "plt.figure(figsize=(10, 6))\n",
        "for metric in [\"BLEU\", \"ROUGE-L\", \"METEOR\", \"BERTScore_F1\"]:\n",
        "    scores = [res[metric] for res in results_by_round]\n",
        "    plt.plot(rounds, scores, label=metric)\n",
        "\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Qwen Few-shot Multi-round Evaluation\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# âœ… è¾“å‡ºæ¯è½®å¾—åˆ†è¡¨æ ¼\n",
        "for idx, scores in enumerate(results_by_round):\n",
        "    print(f\"\\nğŸ“Š Round {idx + 1} Scores:\")\n",
        "    for k, v in scores.items():\n",
        "        print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "B-eJoWIkHOSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 85\n",
        "# 185æ ·æœ¬ï¼Œå·²æ¸…æ´—\n",
        "# musicgen_scene_music_pairs_all_cleaned_train.jsonl\n",
        "# musicgen_scene_music_pairs_all_cleaned_test.jsonl\n",
        "# few-shot k=10\n",
        "# 10 epoch\n",
        "\n",
        "# âœ… å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
        "# !pip install evaluate bert_score rouge_score nltk --quiet\n",
        "# !pip install git+https://github.com/google-research/bleurt.git\n",
        "\n",
        "# âœ… å¯¼å…¥æ¨¡å—\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âœ… è¯»å–æ–°æ•°æ®é›†ï¼ˆ185æ¡å®Œæ•´æ•°æ®ï¼Œæ ¼å¼å·²æ ‡å‡†åŒ–ï¼‰\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "with open(\"musicgen_scene_music_pairs_all_cleaned_test.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# âœ… Qwen API è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ API Keyï¼‰\n",
        "QWEN_API_KEY = \"sk-\"\n",
        "QWEN_API_URL = \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\"\n",
        "\n",
        "# âœ… æ„é€  few-shot promptï¼ˆæ¯è½® 10 æ¡ï¼‰\n",
        "def build_few_shot_messages(k=10):\n",
        "    examples = random.sample(train_data, k)\n",
        "    messages = [{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a music cognition expert. Convert restaurant scene descriptions into MusicGen-style music prompts. Describe BPM, genre, mood, key, instrumentation.\"\n",
        "    }]\n",
        "    for ex in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Scene: {ex['scene']}\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ex['music']})\n",
        "    return messages\n",
        "\n",
        "# âœ… è°ƒç”¨ Qwen æ¥å£\n",
        "def generate_music_description(scene_desc, k=10):\n",
        "    messages = build_few_shot_messages(k)\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Scene: {scene_desc}\"})\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {QWEN_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen2.5-14b-instruct\",\n",
        "        \"input\": {\"messages\": messages},\n",
        "        \"parameters\": {\"temperature\": 0.5, \"max_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(QWEN_API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"output\", {}).get(\"text\", \"\").strip()\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "\n",
        "# âœ… å¤šè½®éªŒè¯ï¼ˆé»˜è®¤ 5 è½®ï¼‰\n",
        "epochs = 10\n",
        "results_by_round = []\n",
        "\n",
        "for round_idx in range(epochs):\n",
        "    print(f\"\\nğŸš€ Round {round_idx + 1}/{epochs}\")\n",
        "    round_results = []\n",
        "    for sample in tqdm(test_data):\n",
        "        pred = generate_music_description(sample[\"scene\"], k=10)\n",
        "        round_results.append({\n",
        "            \"scene\": sample[\"scene\"],\n",
        "            \"reference\": sample[\"music\"],\n",
        "            \"prediction\": pred\n",
        "        })\n",
        "\n",
        "    references = [x[\"reference\"] for x in round_results]\n",
        "    predictions = [x[\"prediction\"] for x in round_results]\n",
        "\n",
        "    rouge = evaluate.load(\"rouge\")\n",
        "    meteor = evaluate.load(\"meteor\")\n",
        "    bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "    meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "    bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "    avg_bertscore_f1 = sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"])\n",
        "\n",
        "    results_by_round.append({\n",
        "        \"BLEU\": avg_bleu,\n",
        "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
        "        \"METEOR\": meteor_result[\"meteor\"],\n",
        "        \"BERTScore_F1\": avg_bertscore_f1\n",
        "    })\n",
        "\n",
        "# âœ… å¯è§†åŒ–è¯„ä¼°æŒ‡æ ‡\n",
        "rounds = list(range(1, epochs + 1))\n",
        "plt.figure(figsize=(10, 6))\n",
        "for metric in [\"BLEU\", \"ROUGE-L\", \"METEOR\", \"BERTScore_F1\"]:\n",
        "    scores = [res[metric] for res in results_by_round]\n",
        "    plt.plot(rounds, scores, label=metric)\n",
        "\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Qwen Few-shot Multi-round Evaluation\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# âœ… è¾“å‡ºæ¯è½®å¾—åˆ†è¡¨æ ¼\n",
        "for idx, scores in enumerate(results_by_round):\n",
        "    print(f\"\\nğŸ“Š Round {idx + 1} Scores:\")\n",
        "    for k, v in scores.items():\n",
        "        print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "edveh9O2Qjl3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}